{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b88a147-3666-48e2-b503-f5dc2e3110b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pypdf\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4f7fdf-c77a-4274-b5d9-50358a6a8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_multiple_pdfs(folder_path):\n",
    "    # List all PDF files in the folder\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    all_chunks = []  # To store all chunks from all PDFs\n",
    "    total_pages = 0  # To track total number of pages processed\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        file_path = os.path.join(folder_path, pdf_file)\n",
    "        print(f\"Processing: {pdf_file}\")\n",
    "        \n",
    "        # Load and split the PDF\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load_and_split()\n",
    "        total_pages += len(pages)\n",
    "\n",
    "        # Split the pages by char\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1024,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len,\n",
    "            add_start_index=True,\n",
    "        )\n",
    "\n",
    "        chunks = text_splitter.split_documents(pages)\n",
    "        all_chunks.extend(chunks)  # Add chunks from this PDF to the total\n",
    "        print(f\"Split {len(pages)} pages into {len(chunks)} chunks from {pdf_file}.\")\n",
    "\n",
    "    print(f\"Processed {total_pages} pages into {len(all_chunks)} chunks across all PDFs.\")\n",
    "\n",
    "    # Create embeddings\n",
    "    embedding = FastEmbedEmbeddings()\n",
    "\n",
    "    # Create and persist vector store\n",
    "    #vector_store = Chroma.from_documents(\n",
    "    Chroma.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=embedding,\n",
    "        persist_directory=\"./sql_chroma_db\"\n",
    "    )\n",
    "    print(\"Vector store created and persisted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4042d054-95a3-4c3d-ba22-57938d759985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this only once to create the vector database \n",
    "folder_path = \"patchy_particles\"\n",
    "#ingest_multiple_pdfs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb46dd4-9418-4146-91e6-a1bb962f1d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\remya\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#Create an access token from Hugging face and use the same as the read and write token below\n",
    "from huggingface_hub import login\n",
    "access_token_read = \"hf**********************************L\"\n",
    "access_token_write = \"hf**********************************L\"\n",
    "login(token = access_token_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055f5f03-3ee0-48fb-ab29-eacde487f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain():\n",
    "    model = Ollama(model=\"llama3\", base_url=\"http://localhost:11434/\",\n",
    "                    temperature = 0.0)\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        <s> [Instructions] You are a friendly assistant. Answer the question based only on the following context. \n",
    "        If you don't know the answer, then reply, No Context availabel for this question {input}. [/Instructions] </s> \n",
    "        [Instructions] Question: {input} \n",
    "        Context: {context} \n",
    "        Answer: [/Instructions]\n",
    "        \"\"\"\n",
    "    )\n",
    "    #Load vector store\n",
    "    embedding = FastEmbedEmbeddings()\n",
    "    vector_store = Chroma(persist_directory=\"./sql_chroma_db\", embedding_function=embedding)\n",
    "\n",
    "    #Create chain\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"score_threshold\": 0.5,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(model, prompt)\n",
    "    chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22acaf8-4d88-4cf2-8e52-8b55396f099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5bd213c5844ca98210d248377f2b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test\n",
    "chain = rag_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506e094a-695d-48f8-8cfa-8729cb4c7236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the gaps in patchy particle self-assembly?\n",
      "\n",
      "Based on the provided context, it seems that there is a gap in understanding the optimal patch size for producing monodisperse clusters. The synthesized particles had an A patch with α = 60° and a B patch with β = 40° half-opening angle, but the results suggest that the patch size of the wider patch was suboptimal for the first stage of assembly.\n",
      "\n",
      "Additionally, there is a gap in understanding the role of the range of patch-patch interactions in the self-assembly process.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"input\": \"What are the gaps in patchy particle self-assembly?\"})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f2a335-d771-4d7c-bef7-4244738dd289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function for the query search\n",
    "def ask(query: str):\n",
    "    #create chain\n",
    "    chain = rag_chain()\n",
    "    #invoke chain\n",
    "    result = chain.invoke({\"input\": query})\n",
    "    #print results with source\n",
    "    print(result[\"answer\"])\n",
    "    for doc in result[\"context\"]:\n",
    "        print(\"Source: \", doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d479e-7939-4748-84aa-8dec3452bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\"What are the gaps in patchy particle self-assembly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d9e9f-0df3-491a-92bf-3e3158676bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
